# Podman-Ollama-AnythingLLM
Check out the README file for a complete guide on how to configure an external SSD to host a daemonless, rootless, localhost-based LLM stack using Podman, Ollama, and AnythingLLM.
